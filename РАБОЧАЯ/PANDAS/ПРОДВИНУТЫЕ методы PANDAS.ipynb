{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1300000.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "melb_data = pd.read_csv('d:/python/GUESS/РАБОЧАЯ/PANDAS/data/melb_data_fe.csv', sep=',')\n",
    "melb_df = melb_data.copy()\n",
    "# melb_df.head()\n",
    "# display(melb_df.info())\n",
    "\n",
    "\n",
    "\n",
    "# melb_df['Date'] =pd.to_datetime(melb_df['Date']).dt.quarter\n",
    "# melb_df['Date'].value_counts()\n",
    "\n",
    "\n",
    "# Преобразуйте все столбцы, в которых меньше 150 уникальных значений, в тип данных category, исключив из преобразования столбцы Date, \n",
    "# Rooms, Bedroom, Bathroom, Car.\n",
    "# В качестве ответа запишите результирующее количество столбцов, которые имеют тип данных category.\n",
    "\n",
    "melb_pass = ['Date', 'Rooms', 'Bedroom', 'Bathroom', 'Car']\n",
    "unique_st = 150\n",
    "for col in melb_df.columns:\n",
    "    if melb_df[col].nunique() < unique_st and col not in melb_pass:\n",
    "        melb_df[col] = melb_df[col].astype('category')\n",
    "# display(melb_df.dtypes[melb_df.dtypes == 'category'].nunique())\n",
    "\n",
    "# melb_df.sort_values(by='Price').head(10)\n",
    "# melb_df.sort_values(by='Date', ascending=False)\n",
    "# melb_df.sort_values(by=['Price','Distance' ]).loc[::10, [ 'Price','Distance']]\n",
    "\n",
    "# mask1 = melb_df['AreaRatio'] < -0.8\n",
    "# mask2 = melb_df['Type'] == 'townhouse'\n",
    "# mask3 = melb_df['SellerG'] == 'McGrath'\n",
    "\n",
    "# melb_df[mask1 & mask2 & mask3].sort_values(\n",
    "#     by=['Date', 'AreaRatio'],\n",
    "#     ascending=[True, False],\n",
    "#     ignore_index=True\n",
    "# ).loc[: , ['Date', 'AreaRatio']]\n",
    "\n",
    "\n",
    "# Задание 2.2\n",
    "# Произведите сортировку столбца AreaRatio по убыванию. При этом индексы полученной таблицы замените на новые.\n",
    "# Какое значение площади здания находится в строке 1558? Ответ округлите до целого числа.\n",
    "\n",
    "melb_df.sort_values(by = 'AreaRatio', ascending=False, ignore_index=True).copy()\n",
    "melb_df.iloc[1558].loc['BuildingArea']\n",
    "\n",
    "# Задание 2.3\n",
    "# Найдите таунхаусы (Type) с количеством жилых комнат (Rooms) больше 2. Отсортируйте полученную таблицу сначала по возрастанию числа комнат,\n",
    "# а затем по убыванию средней площади комнат (MeanRoomsSquare). Индексы таблицы замените на новые. Какая цена будет у объекта в строке 18?\n",
    "# Ответ запишите в виде целого числа.\n",
    "\n",
    "mask_rooms = melb_df['Rooms'] > 2\n",
    "mask_type = melb_df['Type'] == 'townhouse'\n",
    "# melb_df.head()\n",
    "townhauses = melb_df[mask_rooms & mask_type].copy()\n",
    "townhauses.sort_values(\n",
    "    by = ['Rooms', 'MeanRoomsSquare'],\n",
    "    ascending=[True, False],\n",
    "    ignore_index=True).iloc[18].loc['Price']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные представляют собой таблицу, в которой содержится 23 столбца:\n",
    "\n",
    "1 - index — номер строки\n",
    "2 - Suburb — наименование пригорода\n",
    "3 - Address — адрес\n",
    "4 - Rooms — количество комнат в помещении\n",
    "5 - Type — тип здания (h — дом, коттедж, вилла, терраса; u — блочный, дуплексный дом; t — таунхаус)\n",
    "6 - Price — цена помещения\n",
    "7 - Method — метод продажи \n",
    "8 - SellerG — риэлторская компания\n",
    "9 - Date — дата продажи (в формате день/месяц/год)\n",
    "10 - Distance — расстояния до объекта от центра Мельбурна \n",
    "11 - Postcode — почтовый индекс\n",
    "12 - Bedroom — количество спален\n",
    "13 - Bathroom — количество ванных комнат\n",
    "14 - Car — количество парковочных мест\n",
    "15 - Landsize — площадь прилегающей территории\n",
    "16 - BuildingArea — площадь здания\n",
    "17 - YearBuilt — год постройки\n",
    "18 - Lattitude — региональное управление\n",
    "19 - Lattitude — географическая широта\n",
    "20 - Longitude — географическая долгота\n",
    "21 - Regionname — наименование района Мельбурна\n",
    "22 - Propertycount — количество объектов недвижимости в районе, выставленных на продажу\n",
    "23 - Coordinates — широта и долгота, объединённые в кортеж"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4/12   3. Группировка данных в DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nunique</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regionname</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Eastern Metropolitan</th>\n",
       "      <td>26</td>\n",
       "      <td>{Buckingham, HAR, Buxton, Gary, Barry, McGrath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eastern Victoria</th>\n",
       "      <td>11</td>\n",
       "      <td>{hockingstuart, Barry, Harcourts, HAR, Eview, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Northern Metropolitan</th>\n",
       "      <td>40</td>\n",
       "      <td>{Buckingham, Alexkarbon, Hodges, Nick, HAR, Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Northern Victoria</th>\n",
       "      <td>11</td>\n",
       "      <td>{YPA, Buckingham, hockingstuart, HAR, other, R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South-Eastern Metropolitan</th>\n",
       "      <td>25</td>\n",
       "      <td>{Hodges, HAR, Buxton, Gary, Barry, McGrath, Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Southern Metropolitan</th>\n",
       "      <td>38</td>\n",
       "      <td>{Buckingham, Hodges, Nick, HAR, Buxton, Gary, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Western Metropolitan</th>\n",
       "      <td>34</td>\n",
       "      <td>{Alexkarbon, Hodges, HAR, Barry, Brad, McGrath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Western Victoria</th>\n",
       "      <td>6</td>\n",
       "      <td>{YPA, hockingstuart, HAR, other, Ray, Raine}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            nunique  \\\n",
       "Regionname                            \n",
       "Eastern Metropolitan             26   \n",
       "Eastern Victoria                 11   \n",
       "Northern Metropolitan            40   \n",
       "Northern Victoria                11   \n",
       "South-Eastern Metropolitan       25   \n",
       "Southern Metropolitan            38   \n",
       "Western Metropolitan             34   \n",
       "Western Victoria                  6   \n",
       "\n",
       "                                                                          set  \n",
       "Regionname                                                                     \n",
       "Eastern Metropolitan        {Buckingham, HAR, Buxton, Gary, Barry, McGrath...  \n",
       "Eastern Victoria            {hockingstuart, Barry, Harcourts, HAR, Eview, ...  \n",
       "Northern Metropolitan       {Buckingham, Alexkarbon, Hodges, Nick, HAR, Ca...  \n",
       "Northern Victoria           {YPA, Buckingham, hockingstuart, HAR, other, R...  \n",
       "South-Eastern Metropolitan  {Hodges, HAR, Buxton, Gary, Barry, McGrath, Ch...  \n",
       "Southern Metropolitan       {Buckingham, Hodges, Nick, HAR, Buxton, Gary, ...  \n",
       "Western Metropolitan        {Alexkarbon, Hodges, HAR, Barry, Brad, McGrath...  \n",
       "Western Victoria                 {YPA, hockingstuart, HAR, other, Ray, Raine}  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "melb_data = pd.read_csv('d:/python/GUESS/РАБОЧАЯ/PANDAS/data/melb_data_fe.csv', sep=',')\n",
    "melb_df = melb_data.copy()\n",
    "\n",
    "melb_df.groupby(by='Type', as_index=False).mean(numeric_only=True)\n",
    "\n",
    "melb_df.groupby('Type')['Price'].mean()\n",
    "\n",
    "\n",
    "            # ГРУППИРОВКА ДАННЫХ ПО ОДНОМУ КРИТЕРИЮ С НЕСКОЛЬКИМИ АГРЕГАЦИЯМИ\n",
    "\n",
    "melb_df.groupby('MonthSale')['Price'].agg(\n",
    "    ['count', 'mean', 'max']\n",
    ").sort_values(by='count', ascending=False)\n",
    "\n",
    "\n",
    "melb_df.groupby('MonthSale')['Price'].agg('describe')\n",
    "\n",
    "\n",
    "melb_df.groupby('Regionname')['SellerG'].agg(\n",
    "    ['nunique', set]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 3.1\n",
    "Сгруппируйте данные по признаку количества комнат и найдите среднюю цену объектов недвижимости в каждой группе. В качестве ответа запишите количество комнат, для которых средняя цена наибольшая.\n",
    "\n",
    " \n",
    "Задание 3.2\n",
    "Какой регион имеет наименьшее стандартное отклонение по географической широте (Lattitude)?\n",
    "В качестве ответа запишите название этого региона.\n",
    "\n",
    "Задание 3.3\n",
    "Какая риелторская компания (SellerG) имеет наименьшую общую выручку за период с 1 мая по 1 сентября (включительно) 2017 года?\n",
    "Для ответа на этот вопрос рассчитайте сумму продаж (Price) каждой компании в заданный период.\n",
    "Не забудьте перевести даты в формат datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SellerG</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LITTLE</th>\n",
       "      <td>4</td>\n",
       "      <td>6.855000e+05</td>\n",
       "      <td>2742000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cayzer</th>\n",
       "      <td>4</td>\n",
       "      <td>1.109750e+06</td>\n",
       "      <td>4439000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Burnham</th>\n",
       "      <td>7</td>\n",
       "      <td>6.500714e+05</td>\n",
       "      <td>4550500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moonee</th>\n",
       "      <td>9</td>\n",
       "      <td>8.142222e+05</td>\n",
       "      <td>7328000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thomson</th>\n",
       "      <td>13</td>\n",
       "      <td>6.409231e+05</td>\n",
       "      <td>8332000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bells</th>\n",
       "      <td>13</td>\n",
       "      <td>6.658462e+05</td>\n",
       "      <td>8656000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alexkarbon</th>\n",
       "      <td>11</td>\n",
       "      <td>9.986364e+05</td>\n",
       "      <td>10985000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>McDonald</th>\n",
       "      <td>13</td>\n",
       "      <td>1.125962e+06</td>\n",
       "      <td>14637500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rendina</th>\n",
       "      <td>14</td>\n",
       "      <td>1.101591e+06</td>\n",
       "      <td>15422276.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nick</th>\n",
       "      <td>9</td>\n",
       "      <td>1.876667e+06</td>\n",
       "      <td>16890000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Douglas</th>\n",
       "      <td>27</td>\n",
       "      <td>6.792963e+05</td>\n",
       "      <td>18341000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Buckingham</th>\n",
       "      <td>22</td>\n",
       "      <td>8.651364e+05</td>\n",
       "      <td>19033000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C21</th>\n",
       "      <td>24</td>\n",
       "      <td>8.131250e+05</td>\n",
       "      <td>19515000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eview</th>\n",
       "      <td>24</td>\n",
       "      <td>8.246458e+05</td>\n",
       "      <td>19791500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Collins</th>\n",
       "      <td>12</td>\n",
       "      <td>1.684750e+06</td>\n",
       "      <td>20217000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Philip</th>\n",
       "      <td>22</td>\n",
       "      <td>1.002355e+06</td>\n",
       "      <td>22051800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chisholm</th>\n",
       "      <td>18</td>\n",
       "      <td>1.290278e+06</td>\n",
       "      <td>23225000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Williams</th>\n",
       "      <td>21</td>\n",
       "      <td>1.109381e+06</td>\n",
       "      <td>23297000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Love</th>\n",
       "      <td>32</td>\n",
       "      <td>7.301719e+05</td>\n",
       "      <td>23365500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Purplebricks</th>\n",
       "      <td>23</td>\n",
       "      <td>1.017435e+06</td>\n",
       "      <td>23401000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O'Brien</th>\n",
       "      <td>30</td>\n",
       "      <td>7.951836e+05</td>\n",
       "      <td>23855508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAR</th>\n",
       "      <td>31</td>\n",
       "      <td>8.247742e+05</td>\n",
       "      <td>25568000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Village</th>\n",
       "      <td>26</td>\n",
       "      <td>1.018192e+06</td>\n",
       "      <td>26473000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RW</th>\n",
       "      <td>34</td>\n",
       "      <td>8.606176e+05</td>\n",
       "      <td>29261000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raine</th>\n",
       "      <td>45</td>\n",
       "      <td>6.819489e+05</td>\n",
       "      <td>30687700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stockdale</th>\n",
       "      <td>50</td>\n",
       "      <td>7.081960e+05</td>\n",
       "      <td>35409800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sweeney</th>\n",
       "      <td>45</td>\n",
       "      <td>8.196167e+05</td>\n",
       "      <td>36882750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gary</th>\n",
       "      <td>38</td>\n",
       "      <td>1.029958e+06</td>\n",
       "      <td>39138400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hodges</th>\n",
       "      <td>35</td>\n",
       "      <td>1.235171e+06</td>\n",
       "      <td>43231000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YPA</th>\n",
       "      <td>76</td>\n",
       "      <td>6.099257e+05</td>\n",
       "      <td>46354350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miles</th>\n",
       "      <td>40</td>\n",
       "      <td>1.189550e+06</td>\n",
       "      <td>47582000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kay</th>\n",
       "      <td>24</td>\n",
       "      <td>2.023729e+06</td>\n",
       "      <td>48569500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RT</th>\n",
       "      <td>34</td>\n",
       "      <td>1.485235e+06</td>\n",
       "      <td>50498000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brad</th>\n",
       "      <td>67</td>\n",
       "      <td>8.351493e+05</td>\n",
       "      <td>55955000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jas</th>\n",
       "      <td>63</td>\n",
       "      <td>9.409778e+05</td>\n",
       "      <td>59281600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harcourts</th>\n",
       "      <td>90</td>\n",
       "      <td>7.635583e+05</td>\n",
       "      <td>68720250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>McGrath</th>\n",
       "      <td>75</td>\n",
       "      <td>1.045153e+06</td>\n",
       "      <td>78386500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greg</th>\n",
       "      <td>61</td>\n",
       "      <td>1.403623e+06</td>\n",
       "      <td>85621000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Woodards</th>\n",
       "      <td>76</td>\n",
       "      <td>1.131283e+06</td>\n",
       "      <td>85977500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Noel</th>\n",
       "      <td>72</td>\n",
       "      <td>1.224025e+06</td>\n",
       "      <td>88129800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fletchers</th>\n",
       "      <td>82</td>\n",
       "      <td>1.327411e+06</td>\n",
       "      <td>108847700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Biggin</th>\n",
       "      <td>108</td>\n",
       "      <td>1.022495e+06</td>\n",
       "      <td>110429500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Buxton</th>\n",
       "      <td>181</td>\n",
       "      <td>1.210519e+06</td>\n",
       "      <td>219104000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ray</th>\n",
       "      <td>288</td>\n",
       "      <td>8.665729e+05</td>\n",
       "      <td>249572986.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marshall</th>\n",
       "      <td>130</td>\n",
       "      <td>1.953522e+06</td>\n",
       "      <td>253957888.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hockingstuart</th>\n",
       "      <td>309</td>\n",
       "      <td>9.153214e+05</td>\n",
       "      <td>282834310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barry</th>\n",
       "      <td>327</td>\n",
       "      <td>9.074099e+05</td>\n",
       "      <td>296723050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>390</td>\n",
       "      <td>9.359960e+05</td>\n",
       "      <td>365038432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nelson</th>\n",
       "      <td>366</td>\n",
       "      <td>1.037616e+06</td>\n",
       "      <td>379767500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jellis</th>\n",
       "      <td>305</td>\n",
       "      <td>1.357777e+06</td>\n",
       "      <td>414121833.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count          mean          sum\n",
       "SellerG                                        \n",
       "LITTLE             4  6.855000e+05    2742000.0\n",
       "Cayzer             4  1.109750e+06    4439000.0\n",
       "Burnham            7  6.500714e+05    4550500.0\n",
       "Moonee             9  8.142222e+05    7328000.0\n",
       "Thomson           13  6.409231e+05    8332000.0\n",
       "Bells             13  6.658462e+05    8656000.0\n",
       "Alexkarbon        11  9.986364e+05   10985000.0\n",
       "McDonald          13  1.125962e+06   14637500.0\n",
       "Rendina           14  1.101591e+06   15422276.0\n",
       "Nick               9  1.876667e+06   16890000.0\n",
       "Douglas           27  6.792963e+05   18341000.0\n",
       "Buckingham        22  8.651364e+05   19033000.0\n",
       "C21               24  8.131250e+05   19515000.0\n",
       "Eview             24  8.246458e+05   19791500.0\n",
       "Collins           12  1.684750e+06   20217000.0\n",
       "Philip            22  1.002355e+06   22051800.0\n",
       "Chisholm          18  1.290278e+06   23225000.0\n",
       "Williams          21  1.109381e+06   23297000.0\n",
       "Love              32  7.301719e+05   23365500.0\n",
       "Purplebricks      23  1.017435e+06   23401000.0\n",
       "O'Brien           30  7.951836e+05   23855508.0\n",
       "HAR               31  8.247742e+05   25568000.0\n",
       "Village           26  1.018192e+06   26473000.0\n",
       "RW                34  8.606176e+05   29261000.0\n",
       "Raine             45  6.819489e+05   30687700.0\n",
       "Stockdale         50  7.081960e+05   35409800.0\n",
       "Sweeney           45  8.196167e+05   36882750.0\n",
       "Gary              38  1.029958e+06   39138400.0\n",
       "Hodges            35  1.235171e+06   43231000.0\n",
       "YPA               76  6.099257e+05   46354350.0\n",
       "Miles             40  1.189550e+06   47582000.0\n",
       "Kay               24  2.023729e+06   48569500.0\n",
       "RT                34  1.485235e+06   50498000.0\n",
       "Brad              67  8.351493e+05   55955000.0\n",
       "Jas               63  9.409778e+05   59281600.0\n",
       "Harcourts         90  7.635583e+05   68720250.0\n",
       "McGrath           75  1.045153e+06   78386500.0\n",
       "Greg              61  1.403623e+06   85621000.0\n",
       "Woodards          76  1.131283e+06   85977500.0\n",
       "Noel              72  1.224025e+06   88129800.0\n",
       "Fletchers         82  1.327411e+06  108847700.0\n",
       "Biggin           108  1.022495e+06  110429500.0\n",
       "Buxton           181  1.210519e+06  219104000.0\n",
       "Ray              288  8.665729e+05  249572986.0\n",
       "Marshall         130  1.953522e+06  253957888.0\n",
       "hockingstuart    309  9.153214e+05  282834310.0\n",
       "Barry            327  9.074099e+05  296723050.0\n",
       "other            390  9.359960e+05  365038432.0\n",
       "Nelson           366  1.037616e+06  379767500.0\n",
       "Jellis           305  1.357777e+06  414121833.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "melb_data = pd.read_csv('d:/python/GUESS/РАБОЧАЯ/PANDAS/data/melb_data_fe.csv', sep=',')\n",
    "melb_df = melb_data.copy()\n",
    "\n",
    "# Задание 3.1\n",
    "# melb_df.groupby('Rooms')['Price'].mean().sort_values(ascending=False)\n",
    "\n",
    "# Задание 3.2\n",
    "# melb_df.groupby('Regionname')['Lattitude'].std().sort_values(ascending=True)\n",
    "\n",
    "# Задание 3.3.\n",
    "\n",
    "melb_df['Date'] = pd.to_datetime(melb_df['Date'])\n",
    "\n",
    "mask1 = melb_df['Date'] > '2017-05-01' \n",
    "mask2 = melb_df['Date'] < '2017-09-01'\n",
    "melb_df[mask1&mask2].groupby('SellerG')['Price'].agg(\n",
    "    ['count', 'mean', 'sum']\n",
    ").sort_values(by='sum')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                    5/12   4. Сводные таблицы\n",
    "            МЕТОД GROUPBY КАК СПОСОБ ПОСТРОЕНИЯ СВОДНЫХ ТАБЛИЦ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "white  up       0.600177\n",
       "       down     0.585466\n",
       "       right    0.639564\n",
       "blue   up       0.040610\n",
       "       down     0.228351\n",
       "red    up       0.080359\n",
       "       down     0.710000\n",
       "       left     0.262728\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "melb_data = pd.read_csv('d:/python/GUESS/РАБОЧАЯ/PANDAS/data/melb_data_fe.csv', sep=',')\n",
    "melb_df = melb_data.copy()\n",
    "\n",
    "#           МЕТОД GROUPBY КАК СПОСОБ ПОСТРОЕНИЯ СВОДНЫХ ТАБЛИЦ\n",
    "# melb_df.groupby('Rooms')[['Price', 'BuildingArea']].median()\n",
    "\n",
    "# melb_df.groupby(['Rooms', 'Type'])['Price'].mean()\n",
    "# melb_df.groupby(['Rooms', 'Type'])['Price'].mean().unstack()\n",
    "# melb_df.groupby(['Rooms', 'Type'])['Price'].mean().unstack().max()\n",
    "\n",
    "\n",
    "\n",
    "#               МЕТОД PIVOT_TABLE ДЛЯ ПОСТРОЕНИЯ СВОДНЫХ ТАБЛИЦ\n",
    "# melb_df.pivot_table(\n",
    "#     values='Price',\n",
    "#     index='Rooms',\n",
    "#     columns='Type',\n",
    "#     fill_value=0\n",
    "# ).round()\n",
    "\n",
    "\n",
    "# melb_df.pivot_table(\n",
    "#     values='Landsize',\n",
    "#     index='Regionname',\n",
    "#     columns='Type',\n",
    "#     aggfunc=['median', 'mean'],\n",
    "#     fill_value=0\n",
    "# )\n",
    "\n",
    "#               МНОГОМЕРНЫЕ СВОДНЫЕ ТАБЛИЦЫ\n",
    "# melb_df.pivot_table(\n",
    "#     values='Price',\n",
    "#     index=['Method','Type'],\n",
    "#     columns='Regionname', # 'SellerG'],\n",
    "#     aggfunc='median',\n",
    "#     fill_value=0\n",
    "# )\n",
    "\n",
    "# pivot = melb_df.pivot_table(\n",
    "#     values='Landsize',\n",
    "#     index='Regionname',\n",
    "#     columns='Type',\n",
    "#     aggfunc=['median', 'mean'],\n",
    "#     fill_value=0\n",
    "# )\n",
    "# pivot.columns\n",
    "\n",
    "# mask = pivot['mean']['house'] < pivot['median']['house']\n",
    "# filtered_pivot = pivot[mask]\n",
    "# display(filtered_pivot)\n",
    "\n",
    "# # Series\n",
    "mser = pd.Series(\n",
    "    np.random.rand(8),\n",
    "\tindex=[['white','white','white','blue','blue','red','red','red'], \n",
    "           ['up','down','right','up','down','up','down','left']])\n",
    "display(mser)\n",
    "# # DataFrame\n",
    "# mframe = pd.DataFrame(\n",
    "#     np.random.randn(16).reshape(4,4),\n",
    "#     index=[['white','white','red','red'], ['up','down','up','down']],\n",
    "#     columns=[['pen','pen','paper','paper'],[1,2,1,2]]\n",
    "# )\n",
    "# display(mframe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "white  up       0.500941\n",
       "       down     0.948482\n",
       "       right    0.678018\n",
       "blue   up       0.957749\n",
       "       down     0.343209\n",
       "red    up       0.107180\n",
       "       down     0.536362\n",
       "       left     0.249762\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "mser = pd.Series(\n",
    "    np.random.rand(8),\n",
    "\tindex=[['white','white','white','blue','blue','red','red','red'], \n",
    "           ['up','down','right','up','down','up','down','left']])\n",
    "display(mser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 4.2\n",
    "\n",
    "Составьте сводную таблицу, которая показывает зависимость медианной площади (BuildingArea) здания от типа объекта недвижимости (Type) и количества жилых комнат в доме (Rooms). Для какой комбинации признаков площадь здания наибольшая?\n",
    "В качестве ответа запишите эту комбинацию (тип здания, число комнат) через запятую, без пробелов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Rooms</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <td>126.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>216.5</td>\n",
       "      <td>126.0</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>townhouse</th>\n",
       "      <td>88.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>159.5</td>\n",
       "      <td>152.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unit</th>\n",
       "      <td>69.5</td>\n",
       "      <td>110.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>171.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Rooms         1      2      3      4      5      6      7      8      10\n",
       "Type                                                                    \n",
       "house      126.0  126.0  126.0  141.0  177.0  126.0  216.5  126.0  126.0\n",
       "townhouse   88.0  114.0  126.0  159.5  152.0    NaN    NaN    NaN    NaN\n",
       "unit        69.5  110.0  126.0  126.0    NaN  171.0    NaN  126.0    NaN"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "melb_data = pd.read_csv('d:/python/GUESS/РАБОЧАЯ/PANDAS/data/melb_data_fe.csv', sep=',')\n",
    "melb_df = melb_data.copy()\n",
    "\n",
    "melb_df.groupby(['Type', 'Rooms'])['BuildingArea'].median().unstack()\n",
    "\n",
    "# x =melb_df.pivot_table(\n",
    "#     values= 'BuildingArea',\n",
    "#     index='Type',\n",
    "#     columns='Rooms',\n",
    "#     aggfunc='median'  \n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 4.3\n",
    "\n",
    "Составьте сводную таблицу, которая показывает зависимость медианной цены объекта недвижимости (Price) от риелторского агентства (SellerG) и типа здания (Type).\n",
    "Во вновь созданной таблице найдите агентство, у которого медианная цена для зданий типа unit максимальна. В качестве ответа запишите название этого агентства.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SellerG\n",
       "Nick             900000.0\n",
       "Marshall         715000.0\n",
       "Cayzer           707500.0\n",
       "Kay              695000.0\n",
       "Noel             693250.0\n",
       "Buxton           670000.0\n",
       "Fletchers        653000.0\n",
       "Chisholm         640000.0\n",
       "Philip           636000.0\n",
       "RT               630000.0\n",
       "C21              625500.0\n",
       "RW               625500.0\n",
       "Moonee           622000.0\n",
       "O'Brien          618500.0\n",
       "Hodges           605500.0\n",
       "Eview            602000.0\n",
       "Woodards         600000.0\n",
       "Collins          592000.0\n",
       "Jellis           591750.0\n",
       "Purplebricks     582500.0\n",
       "Williams         577000.0\n",
       "hockingstuart    566000.0\n",
       "Alexkarbon       560000.0\n",
       "Miles            555000.0\n",
       "Buckingham       553000.0\n",
       "Gary             550000.0\n",
       "Biggin           548000.0\n",
       "Greg             547500.0\n",
       "McGrath          542500.0\n",
       "other            535000.0\n",
       "Nelson           530000.0\n",
       "HAR              518000.0\n",
       "McDonald         502500.0\n",
       "Barry            502000.0\n",
       "Harcourts        500000.0\n",
       "Ray              497500.0\n",
       "Thomson          495000.0\n",
       "Douglas          494500.0\n",
       "Brad             465000.0\n",
       "Rendina          459000.0\n",
       "Bells            457500.0\n",
       "Jas              455000.0\n",
       "Raine            447500.0\n",
       "LITTLE           447000.0\n",
       "YPA              443500.0\n",
       "Love             440000.0\n",
       "Village          420000.0\n",
       "Stockdale        410000.0\n",
       "Sweeney          381000.0\n",
       "Burnham          305000.0\n",
       "Name: unit, dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "melb_data = pd.read_csv('d:/python/GUESS/РАБОЧАЯ/PANDAS/data/melb_data_fe.csv', sep=',')\n",
    "melb_df = melb_data.copy()\n",
    "\n",
    "x = melb_df.pivot_table(\n",
    "    values= 'Price',\n",
    "    index='SellerG',\n",
    "    columns='Type', \n",
    "    aggfunc='median'\n",
    ").sort_values(by='unit', ascending= False)\n",
    "x['unit']# ['Nick']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6/12   5. Объединение DataFrame: знакомимся с новыми данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>movieId_right</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-07-30 18:45:03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-07-30 18:20:47</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000-07-30 18:37:04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2000-07-30 19:03:35</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2000-07-30 18:48:51</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-05-03 22:21:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-05-08 19:50:47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-05-03 21:19:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-05-03 21:20:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100836</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100837 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating                 date  movieId_right  \\\n",
       "0            1        1     4.0  2000-07-30 18:45:03            1.0   \n",
       "1            1        3     4.0  2000-07-30 18:20:47            2.0   \n",
       "2            1        6     4.0  2000-07-30 18:37:04            3.0   \n",
       "3            1       47     5.0  2000-07-30 19:03:35            4.0   \n",
       "4            1       50     5.0  2000-07-30 18:48:51            5.0   \n",
       "...        ...      ...     ...                  ...            ...   \n",
       "100832     610   166534     4.0  2017-05-03 22:21:31            NaN   \n",
       "100833     610   168248     5.0  2017-05-08 19:50:47            NaN   \n",
       "100834     610   168250     5.0  2017-05-03 21:19:12            NaN   \n",
       "100835     610   168252     5.0  2017-05-03 21:20:15            NaN   \n",
       "100836     610   170875     3.0                  NaN            NaN   \n",
       "\n",
       "                                     title  \\\n",
       "0                         Toy Story (1995)   \n",
       "1                           Jumanji (1995)   \n",
       "2                  Grumpier Old Men (1995)   \n",
       "3                 Waiting to Exhale (1995)   \n",
       "4       Father of the Bride Part II (1995)   \n",
       "...                                    ...   \n",
       "100832                                 NaN   \n",
       "100833                                 NaN   \n",
       "100834                                 NaN   \n",
       "100835                                 NaN   \n",
       "100836                                 NaN   \n",
       "\n",
       "                                             genres  \n",
       "0       Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                        Adventure|Children|Fantasy  \n",
       "2                                    Comedy|Romance  \n",
       "3                              Comedy|Drama|Romance  \n",
       "4                                            Comedy  \n",
       "...                                             ...  \n",
       "100832                                          NaN  \n",
       "100833                                          NaN  \n",
       "100834                                          NaN  \n",
       "100835                                          NaN  \n",
       "100836                                          NaN  \n",
       "\n",
       "[100837 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dates = pd.read_csv('D:/python/GUESS/РАБОЧАЯ/PANDAS/DATA/объединение DataFrame/dates.csv', sep=',')\n",
    "movies = pd.read_csv('D:/python/GUESS/РАБОЧАЯ/PANDAS/DATA/объединение DataFrame/movies.csv', sep=',')\n",
    "ratings1 = pd.read_csv('D:/python/GUESS/РАБОЧАЯ/PANDAS/DATA/объединение DataFrame/ratings1.csv', sep=',')\n",
    "ratings2 = pd.read_csv('D:/python/GUESS/РАБОЧАЯ/PANDAS/DATA/объединение DataFrame/ratings2.csv', sep=',')\n",
    "\n",
    "\n",
    "# # Задание 5.2\n",
    "# # Сколько уникальных (по названию) фильмов представлено в таблице movies?\n",
    "# muves['title'].nunique()\n",
    "\n",
    "# # Задание 5.3\n",
    "# # Сколько уникальных пользователей в таблице ratings1?\n",
    "# ratings1['userId'].nunique()\n",
    "\n",
    "# # Задание 5.4 \n",
    "# # В каком году было выставлено больше всего оценок? Для ответа на этот вопрос используйте таблицу dates.\n",
    "# dates = pd.to_datetime(dates['date'])\n",
    "# dates.dt.year.value_counts().copy()\n",
    "\n",
    "\n",
    "\n",
    "#ratings = pd.concat([ratings1, ratings2])\n",
    "#display(ratings)\n",
    "\n",
    "ratings = pd.concat(\n",
    "    [ratings1, ratings2],\n",
    "    ignore_index=True\n",
    ")\n",
    "# display(ratings)\n",
    "# print('Число строк в таблице ratings: ', ratings.shape[0])\n",
    "# print('Число строк в таблице dates: ', dates.shape[0])\n",
    "# print(ratings.shape[0] == dates.shape[0])\n",
    "\n",
    "# Число строк в таблице ratings: 100837\n",
    "# Число строк в таблице dates: 100836\n",
    "# False\n",
    "# display(ratings1.tail(1))\n",
    "# display(ratings2.head(1))\n",
    "\n",
    "# ratings = ratings.drop_duplicates(ignore_index=True)\n",
    "# # print('Число строк в таблице ratings: ', ratings.shape[0])\n",
    "\n",
    "\n",
    "ratings_dates = pd.concat([ratings, dates], axis=1)\n",
    "# display(ratings_dates.tail(7))\n",
    "\n",
    "\n",
    "\n",
    "joined_false = ratings_dates.join(\n",
    "    movies,\n",
    "    rsuffix='_right',\n",
    "    how='left'\n",
    ")\n",
    "display(joined_false)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 6.3 объединить информацию из предоставленных вам файлов в один DataFrame \n",
    "\n",
    "В ваше распоряжение предоставлена директория users ('./Root/users'). В данной директории содержатся csv-файлы, в каждом из которых хранится информация об идентификаторах пользователей (user_id) и ссылки на их фотографии (image_url). Файлов в директории может быть сколько угодно.\n",
    "\n",
    "Вам необходимо написать функцию concat_user_files(path), параметром которой является path — путь до директории. Функция должна объединить информацию из предоставленных вам файлов в один DataFrame и вернуть его.\n",
    "\n",
    "Список названий всех файлов, находящихся в директории, вы можете получить с помощью функции os.listdir(path) из модуля os. Отсортируйте полученный список, прежде чем производить объединение файлов.\n",
    "\n",
    "Обратите внимание, что метод os.listdir() возвращает только названия файлов в указанной директории, а при чтении файла необходимо указывать полный путь до него.\n",
    "\n",
    "Не забудьте обновить индексы результирующей таблицы после объединения.\n",
    "\n",
    "Примечание. Учтите, что на тестовом наборе файлов в результате объединения могут возникнуть дубликаты, от которых необходимо будет избавиться.\n",
    "\n",
    "Например, для директории users/ результирующая таблица должна иметь следующий вид:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Системе не удается найти указанный путь: './Root/users'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mdrop_duplicates(ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# удаляем дубли\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m---> 18\u001b[0m \u001b[43mconcat_user_files\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./Root/users\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m, in \u001b[0;36mconcat_user_files\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat_user_files\u001b[39m(path):\n\u001b[1;32m----> 7\u001b[0m     files \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     files\u001b[38;5;241m.\u001b[39msort()  \n\u001b[0;32m      9\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Системе не удается найти указанный путь: './Root/users'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os as os\n",
    "\n",
    "#['users1.csv', 'users2.csv', 'users4.csv', 'users3.csv']\n",
    "\n",
    "def concat_user_files(path):\n",
    "    files = os.listdir(path)\n",
    "    files.sort()  \n",
    "    x1 = []\n",
    "    for x in files:\n",
    "        path_files = path + '/' + x\n",
    "        x1.append(pd.read_csv(path_files, sep = ','))   # список DataFrame-ов  \n",
    "        print(x1)\n",
    "    result = pd.concat(x1, ignore_index=True) # объедняем\n",
    "    result = result.drop_duplicates(ignore_index=True) # удаляем дубли\n",
    "    return result\n",
    "\n",
    "concat_user_files('./Root/users')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                8/12   7. Объединение DataFrame: join, merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>V</th>\n",
       "      <th>U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "      <td>d</td>\n",
       "      <td>1393.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>b</td>\n",
       "      <td>9382.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>124.0</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>1904.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A      B  C  V       U\n",
       "0    a  103.0  1  d  1393.7\n",
       "1  NaN    NaN  3  b  9382.2\n",
       "2    c  124.0  2  c  1904.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dates = pd.read_csv('D:/python/GUESS/РАБОЧАЯ/PANDAS/DATA/объединение DataFrame/dates.csv', sep=',')\n",
    "movies = pd.read_csv('D:/python/GUESS/РАБОЧАЯ/PANDAS/DATA/объединение DataFrame/movies.csv', sep=',')\n",
    "ratings1 = pd.read_csv('D:/python/GUESS/РАБОЧАЯ/PANDAS/DATA/объединение DataFrame/ratings1.csv', sep=',')\n",
    "ratings2 = pd.read_csv('D:/python/GUESS/РАБОЧАЯ/PANDAS/DATA/объединение DataFrame/ratings2.csv', sep=',')\n",
    "\n",
    "ratings = pd.concat(\n",
    "    [ratings1, ratings2],\n",
    "    ignore_index=True\n",
    ")\n",
    "ratings_dates = pd.concat([ratings, dates], axis=1)\n",
    "\n",
    "joined_false = ratings_dates.join(\n",
    "    movies,\n",
    "    rsuffix='_right',\n",
    "    how='left'\n",
    ")\n",
    "# display(joined_false)\n",
    "\n",
    "a = pd.DataFrame({'A': ['a', 'b', 'c'], 'B': [103, 214, 124], 'C': [1, 4, 2]})\n",
    "b = pd.DataFrame({'V': ['d', 'b', 'c'], 'U': [1393.7, 9382.2, 1904.5], 'C': [1, 3, 2]})\n",
    "a.merge(b, how='right', on='C')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 7.5: Даны две таблицы: items_df, в которой содержится информация о наличии товаров на складе, и purchase_df с данными о покупках товаров.\n",
    "\n",
    "Информация в таблицах представлена в виде следующих столбцов:\n",
    "\n",
    "item_id — идентификатор модели;\n",
    "vendor — производитель модели;\n",
    " stock_count — имеющееся на складе количество данных моделей (в штуках);\n",
    " purchase_id — идентификатор покупки;\n",
    "price — стоимость модели в покупке.\n",
    "Вам необходимо сделать следующее:\n",
    "\n",
    "Сформируйте DataFrame merged, так чтобы после объединения purchase_df и items_df остались модели, которые учтены на складе и имели продажи.\n",
    "\n",
    "На основе таблицы merged найдите суммарную выручку, которую можно было бы получить от продажи всех товаров, имеющихся на складе. Результат занесите в переменную income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19729490"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "items_df = pd.DataFrame({\n",
    "            'item_id': [417283, 849734, 132223, 573943, 19475, 3294095, 382043, 302948, 100132, 312394],\n",
    "            'vendor': ['Samsung', 'LG', 'Apple', 'Apple', 'LG', 'Apple', 'Samsung', 'Samsung', 'LG', 'ZTE'],\n",
    "            'stock_count': [54, 33, 122, 18, 102, 43, 77, 143, 60, 19]\n",
    "        })\n",
    "\n",
    "purchase_df = pd.DataFrame({\n",
    "            'purchase_id': [101, 101, 101, 112, 121, 145, 145, 145, 145, 221],\n",
    "            'item_id': [417283, 849734, 132223, 573943, 19475, 3294095, 382043, 302948, 103845, 100132],\n",
    "            'price': [13900, 5330, 38200, 49990, 9890, 33000, 67500, 34500, 89900, 11400]\n",
    "        })\n",
    "merged = items_df.merge(\n",
    "    purchase_df,\n",
    "    on = 'item_id',\n",
    "    how = 'inner'\n",
    "    )\n",
    "temp = merged['stock_count'] * merged['price']\n",
    "income = temp.sum()\n",
    "income\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
